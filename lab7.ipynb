{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varshini-svnit/ML_LABS/blob/main/lab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88bbc225-8ac8-43d3-9354-3b648ce7841c",
      "metadata": {
        "id": "88bbc225-8ac8-43d3-9354-3b648ce7841c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fefa78c-2bfd-494b-8b3f-69f55eb3792e",
      "metadata": {
        "id": "0fefa78c-2bfd-494b-8b3f-69f55eb3792e"
      },
      "outputs": [],
      "source": [
        "def accuracy_from_scratch(y_true, y_pred):\n",
        "    \"\"\"Calculates classification accuracy.\"\"\"\n",
        "    return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "def precision_recall_f1_from_scratch(y_true, y_pred, average='macro'):\n",
        "    \"\"\"Calculates precision, recall, and F1-score for multi-class classification.\"\"\"\n",
        "    classes = np.unique(np.concatenate((y_true, y_pred)))\n",
        "    all_precisions = []\n",
        "    all_recalls = []\n",
        "    all_f1s = []\n",
        "\n",
        "    for cls in classes:\n",
        "        tp = np.sum((y_true == cls) & (y_pred == cls))\n",
        "        fp = np.sum((y_true != cls) & (y_pred == cls))\n",
        "        fn = np.sum((y_true == cls) & (y_pred != cls))\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        all_precisions.append(precision)\n",
        "        all_recalls.append(recall)\n",
        "        all_f1s.append(f1)\n",
        "\n",
        "    if average == 'macro':\n",
        "        return np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1s)\n",
        "    else:\n",
        "        # Defaulting to macro for simplicity\n",
        "        return np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1s)\n",
        "\n",
        "def evaluate_classifier_from_scratch(y_true, y_pred, average='macro'):\n",
        "    \"\"\"Evaluates a classifier using from-scratch metrics.\"\"\"\n",
        "    accuracy = accuracy_from_scratch(y_true, y_pred)\n",
        "    precision, recall, f1 = precision_recall_f1_from_scratch(y_true, y_pred, average)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "def mse_from_scratch(y_true, y_pred):\n",
        "    \"\"\"Calculates Mean Squared Error.\"\"\"\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def mae_from_scratch(y_true, y_pred):\n",
        "    \"\"\"Calculates Mean Absolute Error.\"\"\"\n",
        "    return np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "def r2_from_scratch(y_true, y_pred):\n",
        "    \"\"\"Calculates R-squared score.\"\"\"\n",
        "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    if ss_tot == 0:\n",
        "        return 1.0 if ss_res == 0 else 0.0\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n",
        "def evaluate_regressor_from_scratch(y_true, y_pred):\n",
        "    \"\"\"Evaluates a regressor using from-scratch metrics.\"\"\"\n",
        "    mse = mse_from_scratch(y_true, y_pred)\n",
        "    mae = mae_from_scratch(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_from_scratch(y_true, y_pred)\n",
        "    return mse, mae, rmse, r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f00227-9075-4c4f-b9c1-24ad1802d7d9",
      "metadata": {
        "id": "c7f00227-9075-4c4f-b9c1-24ad1802d7d9"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9a4264-7bd6-4c21-af63-c60f10f881b3",
      "metadata": {
        "id": "cc9a4264-7bd6-4c21-af63-c60f10f881b3"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, min_samples_split=2, max_depth=100, criterion=\"id3\"):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        if (depth >= self.max_depth or len(np.unique(y)) == 1 or n_samples < self.min_samples_split):\n",
        "            return Node(value=self._most_common_label(y))\n",
        "\n",
        "        feat_idxs = np.random.choice(n_features, n_features, replace=False)\n",
        "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
        "\n",
        "        if best_feat is None:\n",
        "            return Node(value=self._most_common_label(y))\n",
        "\n",
        "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
        "\n",
        "        # --- FIX: Prevent splits that result in empty branches ---\n",
        "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
        "            return Node(value=self._most_common_label(y))\n",
        "\n",
        "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
        "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
        "        return Node(best_feat, best_thresh, left, right)\n",
        "\n",
        "    def _best_criteria(self, X, y, feat_idxs):\n",
        "        best_gain = -1\n",
        "        split_idx, split_thresh = None, None\n",
        "        for feat_idx in feat_idxs:\n",
        "            X_column = X[:, feat_idx]\n",
        "            thresholds = np.unique(X_column)\n",
        "            for threshold in thresholds:\n",
        "                gain = self._information_gain(y, X_column, threshold)\n",
        "                if self.criterion == \"c4.5\":\n",
        "                    gain = self._gain_ratio(y, X_column, threshold, gain)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    split_idx = feat_idx\n",
        "                    split_thresh = threshold\n",
        "        return split_idx, split_thresh\n",
        "\n",
        "    def _information_gain(self, y, X_column, split_thresh):\n",
        "        parent_entropy = self._entropy(y)\n",
        "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
        "        if len(left_idxs) == 0 or len(right_idxs) == 0: return 0\n",
        "        n, n_l, n_r = len(y), len(left_idxs), len(right_idxs)\n",
        "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
        "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
        "        return parent_entropy - child_entropy\n",
        "\n",
        "    def _gain_ratio(self, y, X_column, split_thresh, information_gain):\n",
        "        split_info = self._split_info(y, X_column, split_thresh)\n",
        "        return information_gain / split_info if split_info != 0 else 0\n",
        "\n",
        "    def _split_info(self, y, X_column, split_thresh):\n",
        "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
        "        n, n_l, n_r = len(y), len(left_idxs), len(right_idxs)\n",
        "        if n_l == 0 or n_r == 0: return 0\n",
        "        p_l, p_r = n_l / n, n_r / n\n",
        "        return -p_l * np.log2(p_l) - p_r * np.log2(p_r)\n",
        "\n",
        "    def _split(self, X_column, split_thresh):\n",
        "        return np.argwhere(X_column <= split_thresh).flatten(), np.argwhere(X_column > split_thresh).flatten()\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        hist = np.bincount(y)\n",
        "        ps = hist / len(y)\n",
        "        return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        if node.is_leaf_node(): return node.value\n",
        "        if x[node.feature] <= node.threshold: return self._traverse_tree(x, node.left)\n",
        "        return self._traverse_tree(x, node.right)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479ec70c-8418-4f75-9b02-8ca84d2efe18",
      "metadata": {
        "id": "479ec70c-8418-4f75-9b02-8ca84d2efe18"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeRegressor:\n",
        "    def __init__(self, min_samples_split=2, max_depth=100):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        if (depth >= self.max_depth or n_samples < self.min_samples_split):\n",
        "            return Node(value=np.mean(y))\n",
        "        feat_idxs = np.random.choice(n_features, n_features, replace=False)\n",
        "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
        "        if best_feat is None:\n",
        "            return Node(value=np.mean(y))\n",
        "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
        "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
        "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
        "        return Node(best_feat, best_thresh, left, right)\n",
        "\n",
        "    def _best_criteria(self, X, y, feat_idxs):\n",
        "        best_vr = -1\n",
        "        split_idx, split_thresh = None, None\n",
        "        for feat_idx in feat_idxs:\n",
        "            X_column = X[:, feat_idx]\n",
        "            thresholds = np.unique(X_column)\n",
        "            for threshold in thresholds:\n",
        "                vr = self._variance_reduction(y, X_column, threshold)\n",
        "                if vr > best_vr:\n",
        "                    best_vr = vr\n",
        "                    split_idx = feat_idx\n",
        "                    split_thresh = threshold\n",
        "        return split_idx, split_thresh\n",
        "\n",
        "    def _variance_reduction(self, y, X_column, split_thresh):\n",
        "        parent_variance = np.var(y)\n",
        "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
        "        if len(left_idxs) == 0 or len(right_idxs) == 0: return 0\n",
        "        n, n_l, n_r = len(y), len(left_idxs), len(right_idxs)\n",
        "        var_l, var_r = np.var(y[left_idxs]), np.var(y[right_idxs])\n",
        "        child_variance = (n_l / n) * var_l + (n_r / n) * var_r\n",
        "        return parent_variance - child_variance\n",
        "\n",
        "    def _split(self, X_column, split_thresh):\n",
        "        return np.argwhere(X_column <= split_thresh).flatten(), np.argwhere(X_column > split_thresh).flatten()\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        if node.is_leaf_node(): return node.value\n",
        "        if x[node.feature] <= node.threshold: return self._traverse_tree(x, node.left)\n",
        "        return self._traverse_tree(x, node.right)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40be8c2f-e938-4a12-9a2c-4e76ca960982",
      "metadata": {
        "id": "40be8c2f-e938-4a12-9a2c-4e76ca960982"
      },
      "source": [
        "__play cricket__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1503db6-db10-40dc-98c6-6b02047defd7",
      "metadata": {
        "id": "e1503db6-db10-40dc-98c6-6b02047defd7",
        "outputId": "b6fb1eed-e7a6-433d-d7fb-082bb94eb9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- ID3 ---\n",
            "Average Accuracy: 0.7000\n",
            "Average Precision: 0.6667\n",
            "Average Recall: 0.6500\n",
            "Average F1-score: 0.6133\n",
            "\n",
            "--- C4.5 ---\n",
            "Average Accuracy: 0.7000\n",
            "Average Precision: 0.6667\n",
            "Average Recall: 0.6500\n",
            "Average F1-score: 0.6133\n"
          ]
        }
      ],
      "source": [
        "df_cricket = pd.read_csv(\"playCricket.csv\")\n",
        "df_cricket = df_cricket.drop('Day', axis=1)\n",
        "for col in df_cricket.columns: df_cricket[col] = df_cricket[col].astype('category').cat.codes\n",
        "X_cricket, y_cricket = df_cricket.iloc[:, :-1].values, df_cricket.iloc[:, -1].values\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ID3\n",
        "print(\"\\n--- ID3 ---\")\n",
        "id3_scores = []\n",
        "for train_index, test_index in kf.split(X_cricket):\n",
        "    X_train, X_test = X_cricket[train_index], X_cricket[test_index]\n",
        "    y_train, y_test = y_cricket[train_index], y_cricket[test_index]\n",
        "    model = DecisionTreeClassifier(criterion='id3')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    id3_scores.append(evaluate_classifier_from_scratch(y_test, y_pred))\n",
        "avg_id3 = np.mean(id3_scores, axis=0)\n",
        "print(f\"Average Accuracy: {avg_id3[0]:.4f}\\nAverage Precision: {avg_id3[1]:.4f}\\nAverage Recall: {avg_id3[2]:.4f}\\nAverage F1-score: {avg_id3[3]:.4f}\")\n",
        "\n",
        "# C4.5\n",
        "print(\"\\n--- C4.5 ---\")\n",
        "c45_scores = []\n",
        "for train_index, test_index in kf.split(X_cricket):\n",
        "    X_train, X_test = X_cricket[train_index], X_cricket[test_index]\n",
        "    y_train, y_test = y_cricket[train_index], y_cricket[test_index]\n",
        "    model = DecisionTreeClassifier(criterion='c4.5')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    c45_scores.append(evaluate_classifier_from_scratch(y_test, y_pred))\n",
        "avg_c45 = np.mean(c45_scores, axis=0)\n",
        "print(f\"Average Accuracy: {avg_c45[0]:.4f}\\nAverage Precision: {avg_c45[1]:.4f}\\nAverage Recall: {avg_c45[2]:.4f}\\nAverage F1-score: {avg_c45[3]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93f098d7-890e-4dc9-b239-afbf269ebe48",
      "metadata": {
        "id": "93f098d7-890e-4dc9-b239-afbf269ebe48"
      },
      "source": [
        "__drug_200__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "813e2308-56f6-4471-b50b-25f1eb292e2e",
      "metadata": {
        "id": "813e2308-56f6-4471-b50b-25f1eb292e2e",
        "outputId": "48e90183-f436-4fb6-c47f-de444d95af42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- ID3 ---\n",
            "Average Accuracy: 0.8950\n",
            "Average Precision: 0.8231\n",
            "Average Recall: 0.8699\n",
            "Average F1-score: 0.8276\n",
            "\n",
            "--- C4.5 ---\n",
            "Average Accuracy: 0.8950\n",
            "Average Precision: 0.8231\n",
            "Average Recall: 0.8699\n",
            "Average F1-score: 0.8276\n"
          ]
        }
      ],
      "source": [
        "df_drug = pd.read_csv(\"drug_200.csv\")\n",
        "for col in ['Sex', 'BP', 'Cholesterol', 'Drug']: df_drug[col] = df_drug[col].astype('category').cat.codes\n",
        "for col in ['Age', 'Na_to_K']: df_drug[col] = (df_drug[col] > df_drug[col].mean()).astype(int)\n",
        "X_drug, y_drug = df_drug.drop('Drug', axis=1).values, df_drug['Drug'].values\n",
        "kf_drug = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ID3\n",
        "print(\"\\n--- ID3 ---\")\n",
        "id3_drug_scores = []\n",
        "for train_index, test_index in kf_drug.split(X_drug):\n",
        "    X_train, X_test = X_drug[train_index], X_drug[test_index]\n",
        "    y_train, y_test = y_drug[train_index], y_drug[test_index]\n",
        "    model = DecisionTreeClassifier(criterion='id3')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    id3_drug_scores.append(evaluate_classifier_from_scratch(y_test, y_pred))\n",
        "avg_id3_drug = np.mean(id3_drug_scores, axis=0)\n",
        "print(f\"Average Accuracy: {avg_id3_drug[0]:.4f}\\nAverage Precision: {avg_id3_drug[1]:.4f}\\nAverage Recall: {avg_id3_drug[2]:.4f}\\nAverage F1-score: {avg_id3_drug[3]:.4f}\")\n",
        "\n",
        "# C4.5\n",
        "print(\"\\n--- C4.5 ---\")\n",
        "c45_drug_scores = []\n",
        "for train_index, test_index in kf_drug.split(X_drug):\n",
        "    X_train, X_test = X_drug[train_index], X_drug[test_index]\n",
        "    y_train, y_test = y_drug[train_index], y_drug[test_index]\n",
        "    model = DecisionTreeClassifier(criterion='c4.5')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    c45_drug_scores.append(evaluate_classifier_from_scratch(y_test, y_pred))\n",
        "avg_c45_drug = np.mean(c45_drug_scores, axis=0)\n",
        "print(f\"Average Accuracy: {avg_c45_drug[0]:.4f}\\nAverage Precision: {avg_c45_drug[1]:.4f}\\nAverage Recall: {avg_c45_drug[2]:.4f}\\nAverage F1-score: {avg_c45_drug[3]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f349264f-3f78-4514-ae1d-31ee3f51feab",
      "metadata": {
        "id": "f349264f-3f78-4514-ae1d-31ee3f51feab"
      },
      "source": [
        "__petrol_consumption__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba0f7fb7-999d-4ec8-9383-98e25b0fa839",
      "metadata": {
        "id": "ba0f7fb7-999d-4ec8-9383-98e25b0fa839",
        "outputId": "ee6bae7e-036c-4c81-b511-85931357c0cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average MSE: 12152.9089\n",
            "Average MAE: 75.8600\n",
            "Average RMSE: 105.8226\n",
            "Average R-squared: -0.3261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/opt/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "df_petrol = pd.read_csv(\"petrol_consumption.csv\")\n",
        "X_petrol, y_petrol = df_petrol.iloc[:, :-1].values, df_petrol.iloc[:, -1].values\n",
        "kf_petrol = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "reg_scores = []\n",
        "for train_index, test_index in kf_petrol.split(X_petrol):\n",
        "    X_train, X_test = X_petrol[train_index], X_petrol[test_index]\n",
        "    y_train, y_test = y_petrol[train_index], y_petrol[test_index]\n",
        "    model = DecisionTreeRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    reg_scores.append(evaluate_regressor_from_scratch(y_test, y_pred))\n",
        "avg_reg = np.mean(reg_scores, axis=0)\n",
        "print(f\"\\nAverage MSE: {avg_reg[0]:.4f}\\nAverage MAE: {avg_reg[1]:.4f}\\nAverage RMSE: {avg_reg[2]:.4f}\\nAverage R-squared: {avg_reg[3]:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}